<html>
   <!-- <head>
    <title>Facial Emotion Expressions</title>
	<link rel="stylesheet" href="assets/css/blogcss.css" />
   </head> -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Facial Emotion Expressions</title>
    <link rel="stylesheet" href="assets/css/blogcss.css" />
    <style>
        body {
            background-color: #fff;
            margin: 0;
            padding: 0;
            font-family: Arial, sans-serif;
            line-height: 1.6;
	    overflow-x: hidden; /* Prevent horizontal scroll */
        }

        .header {
            text-align: center;
            padding: 20px;
            background-color: #333;
            color: #fff;
        }

        .row {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
        }

        .centercolumn {
            width: 70%;
            margin: 10px;
	    box-sizing: border-box; /* Prevent content overflow */

        }

        .card {
            width: 100%;
            max-width: 1000px;
            margin: 0 auto;
        }

        img {
            width: 100%;
            height: auto;
        }

        p {
            margin-bottom: 10px;
        }

	a {
            word-wrap: break-word;
            overflow-wrap: break-word;
            word-break: break-all; /* This ensures long URLs break in small screens */
        }

        @media only screen and (max-width: 768px) {
            .centercolumn {
                width: 90%;
            }
		/* Ensure the card doesn't overflow */
            .card {
                padding: 10px;
            }

            /* Fix large text on mobile */
            h2 {
                font-size: 1.5rem;
                margin: 0;
            }

            /* Fix large words breaking */
            h2 span {
                display: inline-block;
                word-break: normal;
            }

            /* Fix awkward breaks */
            a {
                word-break: break-word;
                white-space: normal;
            }
        }

        /* Ensure padding and borders don't overflow */
        *, *::before, *::after {
            box-sizing: border-box;
        }
    </style>
</head>

<!-- <body style="background-color: #fff; align-items: center;">
<div class="header">
  <h2>Classifying Emotion with Facial Expression using Convolutional Neural Networks</h2>
  <hr>
</div>

<div class="row">
  <div class="centercolumn">
    <div class="card" style="width: 1000">
      <img src="images/cnn.jpeg" alt="cnn image" width="950" height="500">
      <p></p>
	<h3>Introduction</h3>
		<p      ><u>Image classification using CNN</u></p>
      <p>We used train and validation dataset from Kaggle, train and validation dataset consists of 7 directories (expressions) : angry, disgust,
	  fear, happy, neutral, sad, surprise. Our goal is to improve average accuracy of classification.
	</p>
	
	<h3>Preprocessing and Data Loading:</h3>
		<p  >Preprocessing:</p>
		<p>This usually involves resizing  images to a standard size, normalizing pixels between 0 and 1, and possibly applying other transformations </p>
		<p>such as data augmentation to increase the size of the training dataset and improve generalization.</p>
		<img src="images/preprocessing.png"
		width="900" 
		height="250" />
		<p></p>
		<p>Data Loading:</p>
		<p>Once the data is pre-processed, it must be uploaded to  the CNN. This involves splitting the data set into a training, validation, and test set, </p>
		<p>and creating  data sets that can be fed into the network during training. Here we took train and validation dataset</p>
		<img src="images/load data.png"
		width="900" 
		height="350" /> 
		<p></p>
		<img src="images/load data.png"
		width="900" 
		height="350" />
		<p></p>
		
		<img src="images/load data1.png"
		width="900" 
		height="350" />
		<p></p>
		
		<img src="images/load data2.png"
		width="900" 
		height="150" />
		<p></p>
	<h3>Structure of CNN:</h3>
		<p> Let's see a simple CNN template with several building blocks that we can easily understand and correlate to the proposed CNN model. </p>
		<p>Three types of layers make up a basic CNN as illustrated in Fig: input, hidden, and output. The data enters the CNN via the input layer </p>
		<p>and then travels through many hidden levels before reaching the output layer.</p>
		<p> The network's prediction is reflected via the output layer. In terms of loss or error, the network's output is compared to the actual labels.</p>
		<p></p>
		<br>
		<img src="images/strucCNN.png"
		width="900" 
		height="350" />
		<p>The hidden layers in the network act as a basic building element for data transformation.</p>
		<p></p>
		<p><strong>Convolutional Layer:</strong> This layer applies filters to the input image and creates a set of feature maps. </p>
		<p>Each filter detects a specific pattern in the input image, such as edges, lines or corners.</p>
		<p></p>
		<p><strong>Pooling Layer:</strong> This layer reduces the feature maps generated by the convolutional layer to reduce the size of the data</p>
		<p>and extract the most relevant information. The most common types of pooling layers are max pooling and average pooling.</p>
		<p></p>
		<p><strong>Activation Layer:</strong> This layer uses a non-linear activation function to output the previous layer.</p>
		<p>The most commonly used activation functions are ReLU (Recified Linear Unit), Sigmoid </p>
		<p></p>
		<p><strong>Batch Normalization Layer:</strong> This layer normalizes the activations of the previous layer to improve network stability and performance.</p>
		<p></p>
		<p><strong>Dropout Layer:</strong> This layer randomly drops out some of the activations of the previous layer during training to reduce overfitting.</p>
		<p></p>
		<p><strong>Fully Connected Layer:</strong> This layer connects all the neurons of the previous layer to the neurons of the next layer.</p>
		<p> It is typically used at the end of the CNN to produce the final output.</p>
		<p></p>
		<p></p>
		<h3>Model</h3>
		<p></p>
		<h4>TensorFlow</h4>
		<p>TensorFlow is an open-source library for numerical computation and machine learning, developed by Google Brain team.</p>
		<p>TensorFlow is designed to handle the computation of large-scale numerical data, especially for training and deploying deep neural networks.</p>
		<p> It provides a set of APIs for building and training machine learning models, including </p>
		<p>convolutional neural networks (CNNs), recurrent neural networks (RNNs), and deep belief networks (DBNs).</p>
		<h4>Sequential Model</h4>
		<p>A sequential model consists of a sequence of layers, each of which processes the output of the previous layer.</p>
		<p> The layers are connected in a specific order, and the output of one layer is fed as input to the next layer.</p>
		<p> The input to the first layer is usually a sequence of vectors or tensors, and the output of the last layer is the final prediction or output of the model.</p>
		<p></p>
		<h4>Model1</h4>
		<p></p>
		<img src="images/model1.png"
		width="900" 
		height="150" /> 
		<p></p>
		<p>Model-1 summary</p>
		<img src="images/model1_sum.png"
		width="900" 
		height="380" /> 
		<p></p>
		<img src="images/model1_compile.png"
		width="900" 
		height="75" /> 
		<p></p>
		<img src="images/model1_fit.png"
		width="900" 
		height="350" /> 
		<p></p>
		<p>Model-1 Training and validation accuracy</p>
		<img src="images/model1accuracy .png"
		width="900" 
		height="450" /> 
		<p></p>
		
		<h4>Model2</h4>
		<p></p>
		<img src="images/model2.png"
		width="900" 
		height="440" /> 
		<p></p>
		<p>Model-2 summary</p>
		<img src="images/model2_sum.png"
		width="900" 
		height="1300" /> 
		<p></p>
		<img src="images/model2_fit.png"
		width="900" 
		height="350" /> 
		<p></p>
		<p>Model-2 Training and validation accuracy</p>
		<img src="images/model2accuracy.png"
		width="900" 
		height="500" /> 
		<p></p>
		
		<h4>Model3</h4>
		<p></p>
		<img src="images/model3.png"
		width="900" 
		height="350" /> 
		<p></p>
		<p>Model-3 summary</p>
		<img src="images/model3_sum.png"
		width="900" 
		height="550" /> 
		<p></p>
		<img src="images/model3_fit.png"
		width="900" 
		height="450" /> 
		<p></p>
		<p>Model-3 Training and validation accuracy</p>
		<img src="images/model3accuracy.png"
		width="900" 
		height="500"/> 
		<p></p>
		<p></p>
		<p></p>
	    	<h4>My Contribution</h4>
		<p>For model 1, I used reference [2] model, got accuracy of 61.31%.</p>
		<p> For model 2 I added  ZeroPadding2D(zero-padding is a technique used to preserve the spatial dimensions of the input image</p>
		<p> or feature map as it passes through the convolutional layer) and got accuracy over 75.24%, And for model 3  I added Convolution2D Layers,</p>
	    	<p>AveragePooling2D layers, and flatten layer here got accuracy of 76.35% for 5 Epoch.</p>
		<p></p>
		<h3>Accuracy of Three Models</h3>
		<p></p>
		<img src="images/accuracy.png"
		width="900" 
		height="700"/>
		<p></p>
		<p></p>
		<p></p>
		<p><a href="docs/Image_Classifier.ipynb" download="Image_Classifier_Notebook">Download Jupyter notebook</a></p>
		<p></p>
		<p></p>
		<p></p>
		
		<p></p>
		<h3>Reference</h3>
		<p><cite>[1]<a href=" https://www.kaggle.com/code/anand1994sp/facial-expression">  https://www.kaggle.com/code/anand1994sp/facial-expression</a></cite></p>
		<p><cite>[2]<a href="https://www.tensorflow.org/tutorials/images/classification">  https://www.tensorflow.org/tutorials/images/classification</a></cite></p>
		<p><cite>[3]<a href=" https://github.com/serengil/tensorflow-101">  https://github.com/serengil/tensorflow-101</a></cite></p>
		<p><cite>[4]<a href=" https://www.nature.com/articles/s41598-022-11173-0">  https://www.nature.com/articles/s41598-022-11173-0</a></cite></p>
		

    
  </div>

  
</div>

</body> -->

<body>
    <!-- Header section -->
    <div class="header" >
        <h2>Classifying Emotion with Facial Expression using Convolutional Neural Networks</h2>
        <hr>
    </div>

    <!-- Main content section -->
    <div class="row">
        <div class="centercolumn">
            <div class="card">
                <!--<img src="images/cnn.jpeg" alt="cnn image">
                <p></p>-->
				<img src="images/cnn.jpeg" alt="cnn image" width="950" height="500">
      <p></p>
	<h3>Introduction</h3>
		<p      ><u>Image classification using CNN</u></p>
      <p      >We used train and validation dataset from Kaggle, train and validation dataset consists of 7 directories (expressions) : angry, disgust,</p>
	  <p >fear, happy, neutral, sad, surprise. Our goal is to improve average accuracy of classification.
	</p>
	
	<h3>Preprocessing and Data Loading:</h3>
		<p  >Preprocessing:</p>
		<p>This usually involves resizing  images to a standard size, normalizing pixels between 0 and 1, and possibly applying other transformations </p>
		<p>such as data augmentation to increase the size of the training dataset and improve generalization.</p>
		<img src="images/preprocessing.png"
		width="900" 
		height="250" />
		<p></p>
		<p>Data Loading:</p>
		<p>Once the data is pre-processed, it must be uploaded to  the CNN. This involves splitting the data set into a training, validation, and test set, </p>
		<p>and creating  data sets that can be fed into the network during training. Here we took train and validation dataset</p>
		<img src="images/load data.png"
		width="900" 
		height="350" /> 
		<p></p>
		<img src="images/load data.png"
		width="900" 
		height="350" />
		<p></p>
		
		<img src="images/load data1.png"
		width="900" 
		height="350" />
		<p></p>
		
		<img src="images/load data2.png"
		width="900" 
		height="150" />
		<p></p>
	<h3>Structure of CNN:</h3>
		<p> Let's see a simple CNN template with several building blocks that we can easily understand and correlate to the proposed CNN model. </p>
		<p>Three types of layers make up a basic CNN as illustrated in Fig: input, hidden, and output. The data enters the CNN via the input layer </p>
		<p>and then travels through many hidden levels before reaching the output layer.</p>
		<p> The network's prediction is reflected via the output layer. In terms of loss or error, the network's output is compared to the actual labels.</p>
		<p></p>
		<br>
		<img src="images/strucCNN.png"
		width="900" 
		height="350" />
		<p>The hidden layers in the network act as a basic building element for data transformation.</p>
		<p></p>
		<p><strong>Convolutional Layer:</strong> This layer applies filters to the input image and creates a set of feature maps. </p>
		<p>Each filter detects a specific pattern in the input image, such as edges, lines or corners.</p>
		<p></p>
		<p><strong>Pooling Layer:</strong> This layer reduces the feature maps generated by the convolutional layer to reduce the size of the data</p>
		<p>and extract the most relevant information. The most common types of pooling layers are max pooling and average pooling.</p>
		<p></p>
		<p><strong>Activation Layer:</strong> This layer uses a non-linear activation function to output the previous layer.</p>
		<p>The most commonly used activation functions are ReLU (Recified Linear Unit), Sigmoid </p>
		<p></p>
		<p><strong>Batch Normalization Layer:</strong> This layer normalizes the activations of the previous layer to improve network stability and performance.</p>
		<p></p>
		<p><strong>Dropout Layer:</strong> This layer randomly drops out some of the activations of the previous layer during training to reduce overfitting.</p>
		<p></p>
		<p><strong>Fully Connected Layer:</strong> This layer connects all the neurons of the previous layer to the neurons of the next layer.</p>
		<p> It is typically used at the end of the CNN to produce the final output.</p>
		<p></p>
		<p></p>
		<h3>Model</h3>
		<p></p>
		<h4>TensorFlow</h4>
		<p>TensorFlow is an open-source library for numerical computation and machine learning, developed by Google Brain team.</p>
		<p>TensorFlow is designed to handle the computation of large-scale numerical data, especially for training and deploying deep neural networks.</p>
		<p> It provides a set of APIs for building and training machine learning models, including </p>
		<p>convolutional neural networks (CNNs), recurrent neural networks (RNNs), and deep belief networks (DBNs).</p>
		<h4>Sequential Model</h4>
		<p>A sequential model consists of a sequence of layers, each of which processes the output of the previous layer.</p>
		<p> The layers are connected in a specific order, and the output of one layer is fed as input to the next layer.</p>
		<p> The input to the first layer is usually a sequence of vectors or tensors, and the output of the last layer is the final prediction or output of the model.</p>
		<p></p>
		<h4>Model1</h4>
		<p></p>
		<img src="images/model1.png"
		width="900" 
		height="150" /> 
		<p></p>
		<p>Model-1 summary</p>
		<img src="images/model1_sum.png"
		width="900" 
		height="380" /> 
		<p></p>
		<img src="images/model1_compile.png"
		width="900" 
		height="75" /> 
		<p></p>
		<img src="images/model1_fit.png"
		width="900" 
		height="350" /> 
		<p></p>
		<p>Model-1 Training and validation accuracy</p>
		<img src="images/model1accuracy .png"
		width="900" 
		height="450" /> 
		<p></p>
		
		<h4>Model2</h4>
		<p></p>
		<img src="images/model2.png"
		width="900" 
		height="440" /> 
		<p></p>
		<p>Model-2 summary</p>
		<img src="images/model2_sum.png"
		width="900" 
		height="1300" /> 
		<p></p>
		<img src="images/model2_fit.png"
		width="900" 
		height="350" /> 
		<p></p>
		<p>Model-2 Training and validation accuracy</p>
		<img src="images/model2accuracy.png"
		width="900" 
		height="500" /> 
		<p></p>
		
		<h4>Model3</h4>
		<p></p>
		<img src="images/model3.png"
		width="900" 
		height="350" /> 
		<p></p>
		<p>Model-3 summary</p>
		<img src="images/model3_sum.png"
		width="900" 
		height="550" /> 
		<p></p>
		<img src="images/model3_fit.png"
		width="900" 
		height="450" /> 
		<p></p>
		<p>Model-3 Training and validation accuracy</p>
		<img src="images/model3accuracy.png"
		width="900" 
		height="500"/> 
		<p></p>
		<p></p>
		<p></p>
	    	<h4>My Contribution</h4>
		<p>For model 1, I used reference [2] model, got accuracy of 61.31%.</p>
		<p> For model 2 I added  ZeroPadding2D(zero-padding is a technique used to preserve the spatial dimensions of the input image</p>
		<p> or feature map as it passes through the convolutional layer) and got accuracy over 75.24%, And for model 3  I added Convolution2D Layers,</p>
	    	<p>AveragePooling2D layers, and flatten layer here got accuracy of 76.35% for 5 Epoch.</p>
		<p></p>
		<h3>Accuracy of Three Models</h3>
		<p></p>
		<img src="images/accuracy.png"
		width="900" 
		height="700"/>
		<p></p>
		<p></p>
		<p></p>
		<p><a href="docs/Image_Classifier.ipynb" download="Image_Classifier_Notebook">Download Jupyter notebook</a></p>
		<p></p>
		<p></p>
		<p></p>
		
		<p></p>
		<h3>Reference</h3>
		<p><cite>[1]<a href=" https://www.kaggle.com/code/anand1994sp/facial-expression">  https://www.kaggle.com/code/anand1994sp/facial-expression</a></cite></p>
		<p><cite>[2]<a href="https://www.tensorflow.org/tutorials/images/classification">  https://www.tensorflow.org/tutorials/images/classification</a></cite></p>
		<p><cite>[3]<a href=" https://github.com/serengil/tensorflow-101">  https://github.com/serengil/tensorflow-101</a></cite></p>
		<p><cite>[4]<a href=" https://www.nature.com/articles/s41598-022-11173-0">  https://www.nature.com/articles/s41598-022-11173-0</a></cite></p>
		
            </div>
        </div>
    </div>
</body>

</html>
