{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67812161",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "921ade88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4720b719",
   "metadata": {},
   "source": [
    "Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4c534319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data collection\n",
    "#extract csv file\n",
    "import zipfile\n",
    "with zipfile.ZipFile('archive (1).zip','r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e734b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read Top_post_comments.csv file\n",
    "df = pd.read_csv('Top_Posts_Comments.csv')\n",
    "\n",
    "#read Top_posts.csv file\n",
    "df_1 = pd.read_csv('Top_Posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3b4f99e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Twitter thread: [https://twitter.com/cyrildiag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>The future ðŸ¤¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Simple yet very useful. Thank you for sharing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Almost guaranteed, Apple will copy your idea i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Ohh the nightmare of making this into a stable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223169</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>LiDAR is mot powerful sensor for the auto driv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223170</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>So it can now idenrify traffic lights? Musk pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223171</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>Hydranet bro!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223172</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>It even shows flashing yellow turn arrows.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223173</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>Ya just saw karpathy talk on hydra and pytorch.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223174 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id                                            comment\n",
       "0       gh1dj9  Twitter thread: [https://twitter.com/cyrildiag...\n",
       "1       gh1dj9                                       The future ðŸ¤¯\n",
       "2       gh1dj9  Simple yet very useful. Thank you for sharing ...\n",
       "3       gh1dj9  Almost guaranteed, Apple will copy your idea i...\n",
       "4       gh1dj9  Ohh the nightmare of making this into a stable...\n",
       "...        ...                                                ...\n",
       "223169  efk5n3  LiDAR is mot powerful sensor for the auto driv...\n",
       "223170  efk5n3  So it can now idenrify traffic lights? Musk pr...\n",
       "223171  efk5n3                                      Hydranet bro!\n",
       "223172  efk5n3         It even shows flashing yellow turn arrows.\n",
       "223173  efk5n3    Ya just saw karpathy talk on hydra and pytorch.\n",
       "\n",
       "[223174 rows x 2 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "93e2d2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Twitter thread: [https://twitter.com/cyrildiagne/status/1259441154606669824](https://twitter.com/cyrildiagne/status/1259441154606669824)\\n\\nCode: [https://github.com/cyrildiagne/ar-cutpaste/tree/clipboard](https://github.com/cyrildiagne/ar-cutpaste/tree/clipboard)\\n\\nBackground removal is done with U^(2-Net) (Qin et Al, Pattern Recognition 2020): [https://github.com/NathanUA/U-2-Net](https://github.com/NathanUA/U-2-Net)\\n\\n**/!\\\\ EDIT:** You can now subscribe to a beta program to get early access to the app: [https://arcopypaste.app](https://arcopypaste.app)  !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>The future ðŸ¤¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Simple yet very useful. Thank you for sharing the code.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Almost guaranteed, Apple will copy your idea in 3, 2, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Ohh the nightmare of making this into a stable product... Enough to drive you mad just thinking about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223169</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>LiDAR is mot powerful sensor for the auto driving cars but it cannot detect colors or signs.  Another problem is current LiDARs are all based mechanical archtecture.   New solid state LiDAR is necessary to used it for the mass production cars.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223170</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>So it can now idenrify traffic lights? Musk promised robotaxis by now. :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223171</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>Hydranet bro!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223172</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>It even shows flashing yellow turn arrows.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223173</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>Ya just saw karpathy talk on hydra and pytorch.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223174 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id  \\\n",
       "0       gh1dj9   \n",
       "1       gh1dj9   \n",
       "2       gh1dj9   \n",
       "3       gh1dj9   \n",
       "4       gh1dj9   \n",
       "...        ...   \n",
       "223169  efk5n3   \n",
       "223170  efk5n3   \n",
       "223171  efk5n3   \n",
       "223172  efk5n3   \n",
       "223173  efk5n3   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        comment  \n",
       "0       Twitter thread: [https://twitter.com/cyrildiagne/status/1259441154606669824](https://twitter.com/cyrildiagne/status/1259441154606669824)\\n\\nCode: [https://github.com/cyrildiagne/ar-cutpaste/tree/clipboard](https://github.com/cyrildiagne/ar-cutpaste/tree/clipboard)\\n\\nBackground removal is done with U^(2-Net) (Qin et Al, Pattern Recognition 2020): [https://github.com/NathanUA/U-2-Net](https://github.com/NathanUA/U-2-Net)\\n\\n**/!\\\\ EDIT:** You can now subscribe to a beta program to get early access to the app: [https://arcopypaste.app](https://arcopypaste.app)  !  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The future ðŸ¤¯  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Simple yet very useful. Thank you for sharing the code.  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Almost guaranteed, Apple will copy your idea in 3, 2, 1....  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Ohh the nightmare of making this into a stable product... Enough to drive you mad just thinking about it  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ...  \n",
       "223169                                                                                                                                                                                                                                                                                                                                      LiDAR is mot powerful sensor for the auto driving cars but it cannot detect colors or signs.  Another problem is current LiDARs are all based mechanical archtecture.   New solid state LiDAR is necessary to used it for the mass production cars.  \n",
       "223170                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                So it can now idenrify traffic lights? Musk promised robotaxis by now. :)  \n",
       "223171                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Hydranet bro!  \n",
       "223172                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               It even shows flashing yellow turn arrows.  \n",
       "223173                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Ya just saw karpathy talk on hydra and pytorch.  \n",
       "\n",
       "[223174 rows x 2 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth',None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a325cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_url</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>score</th>\n",
       "      <th>comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>date-time</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>[Project] From books to presentations in 10s w...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://v.redd.it/v492uoheuxx41</td>\n",
       "      <td>Project</td>\n",
       "      <td>7798</td>\n",
       "      <td>186</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2020-05-10 13:19:54</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kuc6tz</td>\n",
       "      <td>[D] A Demo from 1993 of 32-year-old Yann LeCun...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://v.redd.it/25nxi9ojfha61</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>5851</td>\n",
       "      <td>133</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2021-01-10 10:30:36</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g7nfvb</td>\n",
       "      <td>[R] First Order Motion Model applied to animat...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://v.redd.it/rlmmjm1q5wu41</td>\n",
       "      <td>Research</td>\n",
       "      <td>4761</td>\n",
       "      <td>111</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2020-04-25 04:27:23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lui92h</td>\n",
       "      <td>[N] AI can turn old photos into moving Images ...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://v.redd.it/ikd5gjlbi8k61</td>\n",
       "      <td>News</td>\n",
       "      <td>4688</td>\n",
       "      <td>230</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2021-02-28 15:12:28</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ohxnts</td>\n",
       "      <td>[D] This AI reveals how much time politicians ...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://i.redd.it/34sgziebfia71.jpg</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>4568</td>\n",
       "      <td>228</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2021-07-11 04:18:59</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>slx33m</td>\n",
       "      <td>We live in beautiful times where you can learn...</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://github.com/louisfb01/start-machine-lea...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2022-02-06 13:50:02</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>k9otbj</td>\n",
       "      <td>Yann LeCunâ€™s Deep Learning Course Free From NYU</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://www.i-programmer.info/news/99-professi...</td>\n",
       "      <td>News</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2020-12-09 09:22:52</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>k2orib</td>\n",
       "      <td>You Can Now Learn for FREE: 9 Courses by Googl...</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://laconicml.com/free-artificial-intellig...</td>\n",
       "      <td>Self Promotion</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2020-11-28 14:43:43</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>ex9w4w</td>\n",
       "      <td>Chatbot trained on \"public domain social media...</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://ai.googleblog.com/2020/01/towards-conv...</td>\n",
       "      <td>news</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2020-02-01 17:55:23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>Tesla's Neural Net can now identify red and gr...</td>\n",
       "      <td>artificial</td>\n",
       "      <td>https://www.teslarati.com/tesla-holiday-update...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2019-12-25 18:50:50</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2987 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id                                         post_title  \\\n",
       "0     gh1dj9  [Project] From books to presentations in 10s w...   \n",
       "1     kuc6tz  [D] A Demo from 1993 of 32-year-old Yann LeCun...   \n",
       "2     g7nfvb  [R] First Order Motion Model applied to animat...   \n",
       "3     lui92h  [N] AI can turn old photos into moving Images ...   \n",
       "4     ohxnts  [D] This AI reveals how much time politicians ...   \n",
       "...      ...                                                ...   \n",
       "2982  slx33m  We live in beautiful times where you can learn...   \n",
       "2983  k9otbj    Yann LeCunâ€™s Deep Learning Course Free From NYU   \n",
       "2984  k2orib  You Can Now Learn for FREE: 9 Courses by Googl...   \n",
       "2985  ex9w4w  Chatbot trained on \"public domain social media...   \n",
       "2986  efk5n3  Tesla's Neural Net can now identify red and gr...   \n",
       "\n",
       "            subreddit                                           post_url  \\\n",
       "0     MachineLearning                    https://v.redd.it/v492uoheuxx41   \n",
       "1     MachineLearning                    https://v.redd.it/25nxi9ojfha61   \n",
       "2     MachineLearning                    https://v.redd.it/rlmmjm1q5wu41   \n",
       "3     MachineLearning                    https://v.redd.it/ikd5gjlbi8k61   \n",
       "4     MachineLearning                https://i.redd.it/34sgziebfia71.jpg   \n",
       "...               ...                                                ...   \n",
       "2982       artificial  https://github.com/louisfb01/start-machine-lea...   \n",
       "2983       artificial  https://www.i-programmer.info/news/99-professi...   \n",
       "2984       artificial  https://laconicml.com/free-artificial-intellig...   \n",
       "2985       artificial  https://ai.googleblog.com/2020/01/towards-conv...   \n",
       "2986       artificial  https://www.teslarati.com/tesla-holiday-update...   \n",
       "\n",
       "          flair_text  score  comments  upvote_ratio            date-time  year  \n",
       "0            Project   7798       186          0.99  2020-05-10 13:19:54  2020  \n",
       "1         Discussion   5851       133          0.98  2021-01-10 10:30:36  2021  \n",
       "2           Research   4761       111          0.97  2020-04-25 04:27:23  2020  \n",
       "3               News   4688       230          0.97  2021-02-28 15:12:28  2021  \n",
       "4         Discussion   4568       228          0.96  2021-07-11 04:18:59  2021  \n",
       "...              ...    ...       ...           ...                  ...   ...  \n",
       "2982      Discussion     84         6          0.90  2022-02-06 13:50:02  2022  \n",
       "2983            News     78         1          0.97  2020-12-09 09:22:52  2020  \n",
       "2984  Self Promotion     80         2          0.95  2020-11-28 14:43:43  2020  \n",
       "2985            news     80        10          0.97  2020-02-01 17:55:23  2020  \n",
       "2986             NaN     80        10          0.89  2019-12-25 18:50:50  2019  \n",
       "\n",
       "[2987 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7edca07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_1 post_id no duplicate values (primary key)\n",
    "duplicates = df_1[df_1['post_id'].duplicated()]\n",
    "len(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "440bfd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Twitter thread: [https://twitter.com/cyrildiag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>The future ðŸ¤¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Simple yet very useful. Thank you for sharing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Almost guaranteed, Apple will copy your idea i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Ohh the nightmare of making this into a stable...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                                            comment\n",
       "0  gh1dj9  Twitter thread: [https://twitter.com/cyrildiag...\n",
       "1  gh1dj9                                       The future ðŸ¤¯\n",
       "2  gh1dj9  Simple yet very useful. Thank you for sharing ...\n",
       "3  gh1dj9  Almost guaranteed, Apple will copy your idea i...\n",
       "4  gh1dj9  Ohh the nightmare of making this into a stable..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "103eefd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_url</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>score</th>\n",
       "      <th>comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>date-time</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>[Project] From books to presentations in 10s w...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://v.redd.it/v492uoheuxx41</td>\n",
       "      <td>Project</td>\n",
       "      <td>7798</td>\n",
       "      <td>186</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2020-05-10 13:19:54</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kuc6tz</td>\n",
       "      <td>[D] A Demo from 1993 of 32-year-old Yann LeCun...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://v.redd.it/25nxi9ojfha61</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>5851</td>\n",
       "      <td>133</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2021-01-10 10:30:36</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g7nfvb</td>\n",
       "      <td>[R] First Order Motion Model applied to animat...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://v.redd.it/rlmmjm1q5wu41</td>\n",
       "      <td>Research</td>\n",
       "      <td>4761</td>\n",
       "      <td>111</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2020-04-25 04:27:23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lui92h</td>\n",
       "      <td>[N] AI can turn old photos into moving Images ...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://v.redd.it/ikd5gjlbi8k61</td>\n",
       "      <td>News</td>\n",
       "      <td>4688</td>\n",
       "      <td>230</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2021-02-28 15:12:28</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ohxnts</td>\n",
       "      <td>[D] This AI reveals how much time politicians ...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>https://i.redd.it/34sgziebfia71.jpg</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>4568</td>\n",
       "      <td>228</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2021-07-11 04:18:59</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id                                         post_title        subreddit  \\\n",
       "0  gh1dj9  [Project] From books to presentations in 10s w...  MachineLearning   \n",
       "1  kuc6tz  [D] A Demo from 1993 of 32-year-old Yann LeCun...  MachineLearning   \n",
       "2  g7nfvb  [R] First Order Motion Model applied to animat...  MachineLearning   \n",
       "3  lui92h  [N] AI can turn old photos into moving Images ...  MachineLearning   \n",
       "4  ohxnts  [D] This AI reveals how much time politicians ...  MachineLearning   \n",
       "\n",
       "                              post_url  flair_text  score  comments  \\\n",
       "0      https://v.redd.it/v492uoheuxx41     Project   7798       186   \n",
       "1      https://v.redd.it/25nxi9ojfha61  Discussion   5851       133   \n",
       "2      https://v.redd.it/rlmmjm1q5wu41    Research   4761       111   \n",
       "3      https://v.redd.it/ikd5gjlbi8k61        News   4688       230   \n",
       "4  https://i.redd.it/34sgziebfia71.jpg  Discussion   4568       228   \n",
       "\n",
       "   upvote_ratio            date-time  year  \n",
       "0          0.99  2020-05-10 13:19:54  2020  \n",
       "1          0.98  2021-01-10 10:30:36  2021  \n",
       "2          0.97  2020-04-25 04:27:23  2020  \n",
       "3          0.97  2021-02-28 15:12:28  2021  \n",
       "4          0.96  2021-07-11 04:18:59  2021  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43064162",
   "metadata": {},
   "source": [
    "Data cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa60e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create comment 1 coloumn with converting comment coloumn data into string\n",
    "import re\n",
    "con_to_str = lambda x: str(x)\n",
    "df['comment1'] = df['comment'].apply(con_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a4851c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Twitter thread: [\\n\\nCode: [\\n\\nBackground rem...\n",
       "1                                              The future ðŸ¤¯\n",
       "2         Simple yet very useful. Thank you for sharing ...\n",
       "3         Almost guaranteed, Apple will copy your idea i...\n",
       "4         Ohh the nightmare of making this into a stable...\n",
       "                                ...                        \n",
       "223169    LiDAR is mot powerful sensor for the auto driv...\n",
       "223170    So it can now idenrify traffic lights? Musk pr...\n",
       "223171                                        Hydranet bro!\n",
       "223172           It even shows flashing yellow turn arrows.\n",
       "223173      Ya just saw karpathy talk on hydra and pytorch.\n",
       "Name: comment1, Length: 223174, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove urls\n",
    "url_pattern = re.compile(r'http\\S+|www\\S+')\n",
    "def remove_urls(sentence):\n",
    "    return url_pattern.sub('', sentence)\n",
    "df['comment1'] = df['comment1'].apply(remove_urls)\n",
    "df['comment1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cde7dcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         twitter thread code background removal is done...\n",
       "1                                                the future\n",
       "2         simple yet very useful thank you for sharing t...\n",
       "3            almost guaranteed apple will copy your idea in\n",
       "4         ohh the nightmare of making this into a stable...\n",
       "                                ...                        \n",
       "223169    lidar is mot powerful sensor for the auto driv...\n",
       "223170    so it can now idenrify traffic lights musk pro...\n",
       "223171                                         hydranet bro\n",
       "223172            it even shows flashing yellow turn arrows\n",
       "223173       ya just saw karpathy talk on hydra and pytorch\n",
       "Name: comment1, Length: 223174, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove special charecters\n",
    "df['comment1'] = df['comment1'].apply(lambda Re: Re.replace(\"-\",\" \"))\n",
    "df['comment1'] = df['comment1'].apply(lambda Re: re.sub(r'[^a-zA-Z\\s]', '', Re))\n",
    "df['comment1'] = df['comment1'].str.lower()\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    return \" \".join(sentence.strip().split())\n",
    "df['comment1'] = df['comment1'].apply(clean_sentence)\n",
    "df['comment1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc30a2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'twitter thread code background removal is done with u net qin et al pattern recognition edit you can now subscribe to a beta program to get early access to the app'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=0\n",
    "b=df.loc[a]['comment1']\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9c2b5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter thread: [https://twitter.com/cyrildiagne/status/1259441154606669824](https://twitter.com/cyrildiagne/status/1259441154606669824)\n",
      "\n",
      "Code: [https://github.com/cyrildiagne/ar-cutpaste/tree/clipboard](https://github.com/cyrildiagne/ar-cutpaste/tree/clipboard)\n",
      "\n",
      "Background removal is done with U^(2-Net) (Qin et Al, Pattern Recognition 2020): [https://github.com/NathanUA/U-2-Net](https://github.com/NathanUA/U-2-Net)\n",
      "\n",
      "**/!\\\\ EDIT:** You can now subscribe to a beta program to get early access to the app: [https://arcopypaste.app](https://arcopypaste.app)  !\n"
     ]
    }
   ],
   "source": [
    "c=df.loc[a]['comment']\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39af4740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Twitter thread: [https://twitter.com/cyrildiag...</td>\n",
       "      <td>twitter thread code background removal is done...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>The future ðŸ¤¯</td>\n",
       "      <td>the future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Simple yet very useful. Thank you for sharing ...</td>\n",
       "      <td>simple yet very useful thank you for sharing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Almost guaranteed, Apple will copy your idea i...</td>\n",
       "      <td>almost guaranteed apple will copy your idea in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Ohh the nightmare of making this into a stable...</td>\n",
       "      <td>ohh the nightmare of making this into a stable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223169</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>LiDAR is mot powerful sensor for the auto driv...</td>\n",
       "      <td>lidar is mot powerful sensor for the auto driv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223170</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>So it can now idenrify traffic lights? Musk pr...</td>\n",
       "      <td>so it can now idenrify traffic lights musk pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223171</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>Hydranet bro!</td>\n",
       "      <td>hydranet bro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223172</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>It even shows flashing yellow turn arrows.</td>\n",
       "      <td>it even shows flashing yellow turn arrows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223173</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>Ya just saw karpathy talk on hydra and pytorch.</td>\n",
       "      <td>ya just saw karpathy talk on hydra and pytorch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223174 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id                                            comment  \\\n",
       "0       gh1dj9  Twitter thread: [https://twitter.com/cyrildiag...   \n",
       "1       gh1dj9                                       The future ðŸ¤¯   \n",
       "2       gh1dj9  Simple yet very useful. Thank you for sharing ...   \n",
       "3       gh1dj9  Almost guaranteed, Apple will copy your idea i...   \n",
       "4       gh1dj9  Ohh the nightmare of making this into a stable...   \n",
       "...        ...                                                ...   \n",
       "223169  efk5n3  LiDAR is mot powerful sensor for the auto driv...   \n",
       "223170  efk5n3  So it can now idenrify traffic lights? Musk pr...   \n",
       "223171  efk5n3                                      Hydranet bro!   \n",
       "223172  efk5n3         It even shows flashing yellow turn arrows.   \n",
       "223173  efk5n3    Ya just saw karpathy talk on hydra and pytorch.   \n",
       "\n",
       "                                                 comment1  \n",
       "0       twitter thread code background removal is done...  \n",
       "1                                              the future  \n",
       "2       simple yet very useful thank you for sharing t...  \n",
       "3          almost guaranteed apple will copy your idea in  \n",
       "4       ohh the nightmare of making this into a stable...  \n",
       "...                                                   ...  \n",
       "223169  lidar is mot powerful sensor for the auto driv...  \n",
       "223170  so it can now idenrify traffic lights musk pro...  \n",
       "223171                                       hydranet bro  \n",
       "223172          it even shows flashing yellow turn arrows  \n",
       "223173     ya just saw karpathy talk on hydra and pytorch  \n",
       "\n",
       "[223174 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f967f",
   "metadata": {},
   "source": [
    "Data transformation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "567e5095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment1</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Twitter thread: [https://twitter.com/cyrildiag...</td>\n",
       "      <td>twitter thread code background removal is done...</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>The future ðŸ¤¯</td>\n",
       "      <td>the future</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Simple yet very useful. Thank you for sharing ...</td>\n",
       "      <td>simple yet very useful thank you for sharing t...</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Almost guaranteed, Apple will copy your idea i...</td>\n",
       "      <td>almost guaranteed apple will copy your idea in</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gh1dj9</td>\n",
       "      <td>Ohh the nightmare of making this into a stable...</td>\n",
       "      <td>ohh the nightmare of making this into a stable...</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223169</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>LiDAR is mot powerful sensor for the auto driv...</td>\n",
       "      <td>lidar is mot powerful sensor for the auto driv...</td>\n",
       "      <td>artificial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223170</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>So it can now idenrify traffic lights? Musk pr...</td>\n",
       "      <td>so it can now idenrify traffic lights musk pro...</td>\n",
       "      <td>artificial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223171</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>Hydranet bro!</td>\n",
       "      <td>hydranet bro</td>\n",
       "      <td>artificial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223172</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>It even shows flashing yellow turn arrows.</td>\n",
       "      <td>it even shows flashing yellow turn arrows</td>\n",
       "      <td>artificial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223173</th>\n",
       "      <td>efk5n3</td>\n",
       "      <td>Ya just saw karpathy talk on hydra and pytorch.</td>\n",
       "      <td>ya just saw karpathy talk on hydra and pytorch</td>\n",
       "      <td>artificial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223174 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id                                            comment  \\\n",
       "0       gh1dj9  Twitter thread: [https://twitter.com/cyrildiag...   \n",
       "1       gh1dj9                                       The future ðŸ¤¯   \n",
       "2       gh1dj9  Simple yet very useful. Thank you for sharing ...   \n",
       "3       gh1dj9  Almost guaranteed, Apple will copy your idea i...   \n",
       "4       gh1dj9  Ohh the nightmare of making this into a stable...   \n",
       "...        ...                                                ...   \n",
       "223169  efk5n3  LiDAR is mot powerful sensor for the auto driv...   \n",
       "223170  efk5n3  So it can now idenrify traffic lights? Musk pr...   \n",
       "223171  efk5n3                                      Hydranet bro!   \n",
       "223172  efk5n3         It even shows flashing yellow turn arrows.   \n",
       "223173  efk5n3    Ya just saw karpathy talk on hydra and pytorch.   \n",
       "\n",
       "                                                 comment1        subreddit  \n",
       "0       twitter thread code background removal is done...  MachineLearning  \n",
       "1                                              the future  MachineLearning  \n",
       "2       simple yet very useful thank you for sharing t...  MachineLearning  \n",
       "3          almost guaranteed apple will copy your idea in  MachineLearning  \n",
       "4       ohh the nightmare of making this into a stable...  MachineLearning  \n",
       "...                                                   ...              ...  \n",
       "223169  lidar is mot powerful sensor for the auto driv...       artificial  \n",
       "223170  so it can now idenrify traffic lights musk pro...       artificial  \n",
       "223171                                       hydranet bro       artificial  \n",
       "223172          it even shows flashing yellow turn arrows       artificial  \n",
       "223173     ya just saw karpathy talk on hydra and pytorch       artificial  \n",
       "\n",
       "[223174 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge df and df_1\n",
    "merged_df = pd.merge(df, df_1[['post_id', 'subreddit']], on='post_id', how='left')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3b5203d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['subreddit'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ef33a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_value = merged_df['subreddit'].mode()[0]\n",
    "merged_df['subreddit'] = merged_df['subreddit'].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a57bc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['subreddit'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce59814",
   "metadata": {},
   "source": [
    "# Navie bayes classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f47930",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "274c7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mer_mul=merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dac0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mode imputation\n",
    "mode_value = mer_mul['subreddit'].mode()[0]\n",
    "mer_mul['subreddit'] = mer_mul['subreddit'].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "540ad138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 156221\n",
      "Development set size: 33476\n",
      "Test set size: 33477\n"
     ]
    }
   ],
   "source": [
    "# Decide on the proportions of your data\n",
    "train_size = 0.7\n",
    "dev_test_size = 0.3\n",
    "\n",
    "# Split your data into the training set and the rest of the data\n",
    "train_data, remaining_data = train_test_split(mer_mul, train_size=train_size, random_state=42)\n",
    "\n",
    "# Split the remaining data into the development set and the test set\n",
    "dev_data, test_data = train_test_split(remaining_data, train_size=dev_test_size/(dev_test_size+dev_test_size),random_state=42)\n",
    "\n",
    "# Print the sizes of each set\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Development set size: {len(dev_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4589f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7089556697335404\n"
     ]
    }
   ],
   "source": [
    "#dev_ data for Multinomial\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train=train_data['comment1']\n",
    "X_test=dev_data['comment1']\n",
    "y_train=train_data['subreddit']\n",
    "y_test =dev_data['subreddit']\n",
    "\n",
    "# convert the sentences in the training set into feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# convert the sentences in the testing set into feature vectors\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# train a Naive Bayes Classifier on the feature vectors and class labels\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80cb1e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7087764368502808\n"
     ]
    }
   ],
   "source": [
    "# train a Naive Bayes Classifier on the feature vectors and class labels\n",
    "clf = MultinomialNB(alpha=0.9)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3efa2f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7091647747640101\n"
     ]
    }
   ],
   "source": [
    "# train a Naive Bayes Classifier on the feature vectors and class labels\n",
    "clf = MultinomialNB(alpha=1.1)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d81c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data for MultinomialNB\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the dataset into a pandas dataframe\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train=train_data['comment1']\n",
    "X_test=test_data['comment1']\n",
    "y_train=train_data['subreddit']\n",
    "y_test =test_data['subreddit']\n",
    "\n",
    "# convert the sentences in the training set into feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad30ac1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7078889984168235\n"
     ]
    }
   ],
   "source": [
    "# train a Naive Bayes Classifier on the feature vectors and class labels\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "# convert the sentences in the testing set into feature vectors\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d321fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7080383546912806\n"
     ]
    }
   ],
   "source": [
    "# train a Naive Bayes Classifier on the feature vectors and class labels\n",
    "clf = MultinomialNB(alpha=1.1)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "# convert the sentences in the testing set into feature vectors\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42760a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7080980972010634\n"
     ]
    }
   ],
   "source": [
    "# train a Naive Bayes Classifier on the feature vectors and class labels\n",
    "clf = MultinomialNB(alpha=0.9)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "# convert the sentences in the testing set into feature vectors\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e291d63",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "266a0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mer_bir=merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c256fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mode imputation\n",
    "mode_value2 = mer_bir['subreddit'].mode()[0]\n",
    "mer_bir['subreddit'] = mer_bir['subreddit'].fillna(mode_value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07f96a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 156221\n",
      "Development set size: 33476\n",
      "Test set size: 33477\n"
     ]
    }
   ],
   "source": [
    "#spliting of data into train, dev, test\n",
    "# Decide on the proportions of your data\n",
    "train_size = 0.7\n",
    "dev_test_size = 0.3\n",
    "\n",
    "# Split your data into the training set and the rest of the data\n",
    "train_data, remaining_data = train_test_split(mer_bir, train_size=train_size, random_state=42)\n",
    "\n",
    "# Split the remaining data into the development set and the test set\n",
    "dev_data, test_data = train_test_split(remaining_data, train_size=dev_test_size/(dev_test_size+dev_test_size),random_state=42)\n",
    "\n",
    "# Print the sizes of each set\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Development set size: {len(dev_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35e0c95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6909128928187358\n"
     ]
    }
   ],
   "source": [
    "#dev Dataset for Bernoulli Naive Bayes model\n",
    "X_train=train_data['comment1']\n",
    "X_test=dev_data['comment1']\n",
    "y_train=train_data['subreddit'].to_numpy()\n",
    "y_test=dev_data['subreddit'].to_numpy()\n",
    "\n",
    "\n",
    "# convert the text data into a bag-of-words representation\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_train_bow=csr_matrix(X_train_bow)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "X_test_bow=csr_matrix(X_test_bow)\n",
    "\n",
    "\n",
    "\n",
    "# convert the bag-of-words representation to a binary representation\n",
    "binarizer = Binarizer()\n",
    "X_train_bin = binarizer.fit_transform(X_train_bow)\n",
    "X_test_bin = binarizer.transform(X_test_bow)\n",
    "\n",
    "# train a Bernoulli Naive Bayes model\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train_bin, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = clf.predict(X_test_bin)\n",
    "\n",
    "# evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41c82e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7032202174692317\n"
     ]
    }
   ],
   "source": [
    "# train a Bernoulli Naive Bayes model\n",
    "clf = BernoulliNB(alpha=1.5)\n",
    "clf.fit(X_train_bin, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = clf.predict(X_test_bin)\n",
    "\n",
    "# evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44e050f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6917883920303491\n"
     ]
    }
   ],
   "source": [
    "#test dataset Bernoulli Naive Bayes model\n",
    "#spliting of data into train, dev, test\n",
    "X_train=train_data['comment1']\n",
    "X_test=test_data['comment1']\n",
    "y_train=train_data['subreddit'].to_numpy()\n",
    "y_test=test_data['subreddit'].to_numpy()\n",
    "\n",
    "\n",
    "# convert the text data into a bag-of-words representation\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_train_bow=csr_matrix(X_train_bow)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "X_test_bow=csr_matrix(X_test_bow)\n",
    "\n",
    "\n",
    "\n",
    "# convert the bag-of-words representation to a binary representation\n",
    "binarizer = Binarizer()\n",
    "X_train_bin = binarizer.fit_transform(X_train_bow)\n",
    "X_test_bin = binarizer.transform(X_test_bow)\n",
    "\n",
    "# train a Bernoulli Naive Bayes model\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train_bin, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = clf.predict(X_test_bin)\n",
    "\n",
    "# evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72f47325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7038862502613735\n"
     ]
    }
   ],
   "source": [
    "# train a Bernoulli Naive Bayes model\n",
    "clf = BernoulliNB(alpha=2.1)\n",
    "clf.fit(X_train_bin, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = clf.predict(X_test_bin)\n",
    "\n",
    "# evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c7e9ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7052603279863787\n"
     ]
    }
   ],
   "source": [
    "# train a Bernoulli Naive Bayes model\n",
    "clf = BernoulliNB(alpha=1.5)\n",
    "clf.fit(X_train_bin, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = clf.predict(X_test_bin)\n",
    "\n",
    "# evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f214180e",
   "metadata": {},
   "source": [
    "# KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fb07388",
   "metadata": {},
   "outputs": [],
   "source": [
    "mer_knn=merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15e09ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mode imputation\n",
    "mode_value = mer_knn['subreddit'].mode()[0]\n",
    "mer_knn['subreddit'] = mer_knn['subreddit'].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7c26ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 156221\n",
      "Development set size: 33476\n",
      "Test set size: 33477\n"
     ]
    }
   ],
   "source": [
    "# Decide on the proportions of your data\n",
    "train_size = 0.7\n",
    "dev_test_size = 0.3\n",
    "\n",
    "# Split your data into the training set and the rest of the data\n",
    "train_data, remaining_data = train_test_split(mer_knn, train_size=train_size, random_state=42)\n",
    "\n",
    "# Split the remaining data into the development set and the test set\n",
    "dev_data, test_data = train_test_split(remaining_data, train_size=dev_test_size/(dev_test_size+dev_test_size),random_state=42)\n",
    "\n",
    "# Print the sizes of each set\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Development set size: {len(dev_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a40ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing sets\n",
    "#df['column_name'] = df['column_name'].astype(float)\n",
    "X_train=train_data['comment1']\n",
    "X_test=dev_data['comment1']\n",
    "y_train=train_data['subreddit']\n",
    "y_test =dev_data['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "555acbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Convert the text data into a matrix of token counts using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8636bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5230612976460748\n"
     ]
    }
   ],
   "source": [
    "# Train a kNN classifier on the training set\n",
    "k = 5 # number of neighbors\n",
    "clf = KNeighborsClassifier(n_neighbors=k)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the classifier on the dev set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb617f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5242561835344725\n"
     ]
    }
   ],
   "source": [
    "# Train a kNN classifier on the training set\n",
    "k = 3 # number of neighbors\n",
    "clf = KNeighborsClassifier(n_neighbors=k)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the classifier on the dev set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8207df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37f467a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for test dataset\n",
    "# split the dataset into training and testing sets\n",
    "#df['column_name'] = df['column_name'].astype(float)\n",
    "X_train=train_data['comment1']\n",
    "X_test=test_data['comment1']\n",
    "y_train=train_data['subreddit']\n",
    "y_test =test_data['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d32e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text data into a matrix of token counts using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c56b2e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5325148609493084\n"
     ]
    }
   ],
   "source": [
    "# Train a kNN classifier on the training set\n",
    "k = 5 # number of neighbors\n",
    "clf = KNeighborsClassifier(n_neighbors=k)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the classifier on the dev set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82420455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.531051169459629\n"
     ]
    }
   ],
   "source": [
    "# Train a kNN classifier on the training set\n",
    "k = 3 # number of neighbors\n",
    "clf = KNeighborsClassifier(n_neighbors=k)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the classifier on the dev set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "023579ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5509752964722048\n"
     ]
    }
   ],
   "source": [
    "# Train a kNN classifier on the training set\n",
    "k = 21 # number of neighbors\n",
    "clf = KNeighborsClassifier(n_neighbors=k)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the classifier on the dev set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4143d687",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35c38219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree\n",
    "mer_des=merged_df.copy()\n",
    "#Mode imputation\n",
    "mode_value = mer_des['subreddit'].mode()[0]\n",
    "mer_des['subreddit'] = mer_des['subreddit'].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97763378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 156221\n",
      "Development set size: 33476\n",
      "Test set size: 33477\n"
     ]
    }
   ],
   "source": [
    "#split dataset into train, dev,test datasets \n",
    "# Decide on the proportions of your data\n",
    "train_size = 0.7\n",
    "dev_test_size = 0.3\n",
    "\n",
    "# Split your data into the training set and the rest of the data\n",
    "train_data, remaining_data = train_test_split(mer_des, train_size=train_size, random_state=42)\n",
    "\n",
    "# Split the remaining data into the development set and the test set\n",
    "dev_data, test_data = train_test_split(remaining_data, train_size=dev_test_size/(dev_test_size+dev_test_size),random_state=42)\n",
    "\n",
    "# Print the sizes of each set\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Development set size: {len(dev_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77f90f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5870175648225594\n"
     ]
    }
   ],
   "source": [
    "#dev_ data for Decision Tree\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train=train_data['comment1']\n",
    "X_test=dev_data['comment1']\n",
    "y_train=train_data['subreddit']\n",
    "y_test =dev_data['subreddit']\n",
    "\n",
    "# convert the sentences in the training set into feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# train a Naive Bayes Classifier on the feature vectors and class labels\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "# convert the sentences in the testing set into feature vectors\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14ed3a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5936911909669326\n"
     ]
    }
   ],
   "source": [
    "#test_ data for Decision Tree\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train=train_data['comment1']\n",
    "X_test=test_data['comment1']\n",
    "y_train=train_data['subreddit']\n",
    "y_test =test_data['subreddit']\n",
    "\n",
    "# convert the sentences in the training set into feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# train a Naive Bayes Classifier on the feature vectors and class labels\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "# convert the sentences in the testing set into feature vectors\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f041ea36",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce0c994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mer_ram=merged_df.copy()\n",
    "\n",
    "#Mode imputation\n",
    "mode_value = mer_ram['subreddit'].mode()[0]\n",
    "mer_ram['subreddit'] = mer_ram['subreddit'].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69e57612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 156221\n",
      "Development set size: 33476\n",
      "Test set size: 33477\n"
     ]
    }
   ],
   "source": [
    "# Decide on the proportions of your data\n",
    "train_size = 0.7\n",
    "dev_test_size = 0.3\n",
    "\n",
    "# Split your data into the training set and the rest of the data\n",
    "train_data, remaining_data = train_test_split(mer_ram, train_size=train_size, random_state=42)\n",
    "\n",
    "# Split the remaining data into the development set and the test set\n",
    "dev_data, test_data = train_test_split(remaining_data, train_size=dev_test_size/(dev_test_size+dev_test_size),random_state=42)\n",
    "\n",
    "# Print the sizes of each set\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Development set size: {len(dev_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1662466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing sets\n",
    "#df['column_name'] = df['column_name'].astype(float)\n",
    "X_train=train_data['comment1']\n",
    "X_test=dev_data['comment1']\n",
    "y_train=train_data['subreddit']\n",
    "y_test =dev_data['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e610647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# preprocess data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "145deafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6823395865694826\n"
     ]
    }
   ],
   "source": [
    "#dev_data\n",
    "# train random forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# test model accuracy\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6171d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing sets\n",
    "#df['column_name'] = df['column_name'].astype(float)\n",
    "X_train=train_data['comment1']\n",
    "X_test=test_data['comment1']\n",
    "y_train=train_data['subreddit']\n",
    "y_test =test_data['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a471f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# preprocess data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ec18f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6848582608955402\n"
     ]
    }
   ],
   "source": [
    "#test_data\n",
    "# train random forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# test model accuracy\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4560db61",
   "metadata": {},
   "source": [
    "# Using Lemmatization for multinomialNB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "19ca6705",
   "metadata": {},
   "outputs": [],
   "source": [
    "mer_lem=merged_df.copy()\n",
    "\n",
    "#Mode imputation\n",
    "mode_value = mer_lem['subreddit'].mode()[0]\n",
    "mer_lem['subreddit'] = mer_lem['subreddit'].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6b552570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c7c85369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5fe2bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Create a WordNetLemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function to apply lemmatization on a sentence\n",
    "def lemmatize_sentence(sentence):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in sentence.split()])\n",
    "\n",
    "# Apply lemmatization on the 'comment_stemmed' column\n",
    "mer_lem['comment1'] = mer_lem['comment1'].apply(lemmatize_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ea866cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 156221\n",
      "Development set size: 33476\n",
      "Test set size: 33477\n"
     ]
    }
   ],
   "source": [
    "# Decide on the proportions of your data\n",
    "train_size = 0.7\n",
    "dev_test_size = 0.3\n",
    "\n",
    "# Split your data into the training set and the rest of the data\n",
    "train_data, remaining_data = train_test_split(mer_lem, train_size=train_size, random_state=42)\n",
    "\n",
    "# Split the remaining data into the development set and the test set\n",
    "dev_data, test_data = train_test_split(remaining_data, train_size=dev_test_size/(dev_test_size+dev_test_size),random_state=42)\n",
    "\n",
    "# Print the sizes of each set\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Development set size: {len(dev_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a313e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing sets\n",
    "#df['column_name'] = df['column_name'].astype(float)\n",
    "X_train=train_data['comment1']\n",
    "X_test=dev_data['comment1']\n",
    "y_train=train_data['subreddit']\n",
    "y_test =dev_data['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82736ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "98da2b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7090751583223802\n"
     ]
    }
   ],
   "source": [
    "#dev data\n",
    "# convert the sentences in the training set into feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# convert the sentences in the testing set into feature vectors\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# train a Naive Bayes Classifier on the feature vectors and class labels\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d56d6c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7389083413881616\n"
     ]
    }
   ],
   "source": [
    "#train data\n",
    "# convert the sentences in the training set into feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# convert the sentences in the testing set into feature vectors\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# train a Naive Bayes Classifier on the feature vectors and class labels\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_train_vect)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cb2fe517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing sets\n",
    "#df['column_name'] = df['column_name'].astype(float)\n",
    "X_train=train_data['comment1']\n",
    "X_test=test_data['comment1']\n",
    "y_train=train_data['subreddit']\n",
    "y_test =test_data['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e2dc2ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7068136332407324\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "# convert the sentences in the training set into feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# convert the sentences in the testing set into feature vectors\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# train a Naive Bayes Classifier on the feature vectors and class labels\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "48d38e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7069928607700809\n"
     ]
    }
   ],
   "source": [
    "# train a Naive Bayes Classifier on the feature vectors and class labels\n",
    "clf = MultinomialNB(alpha=1.1)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = clf.predict(X_test_vect)\n",
    "\n",
    "# evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfb4e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1320c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bda57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c98a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
